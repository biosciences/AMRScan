normalized_counts <- GetAssayData(pbmc, layer = "data")
normalized_nonzero_genes <- rowSums(normalized_counts[, 1:10] > 0) > 0
head(counts[normalized_nonzero_genes, 1:10], 10)
head(normalized_counts[normalized_nonzero_genes, 1:10], 10)
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)
head(VariableFeatures(pbmc), 10)
pbmc <- ScaleData(pbmc)
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))
pbmc <- FindNeighbors(pbmc, dims = 1:10)
pbmc <- FindClusters(pbmc, resolution = 0.5)
pbmc <- RunUMAP(pbmc, dims = 1:10)
DimPlot(pbmc, reduction = "umap", label = TRUE)
markers <- FindAllMarkers(pbmc, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)
head(markers)
library(Seurat)
library(ggplot2)
library(patchwork)
library(SeuratData)
install.packages("SeuratData")
install.packages("patchwork")
SeuratData::InstallData("stxBrain")
library(SeuratData)
install.packages("SeuratData")
library(remotes)
install.packages("remotes")  # if not already installed
remotes::install_github("satijalab/seurat-data")
library(SeuratData)
SeuratData::AvailableData()
SeuratData::InstallData("pbmc3k")
SeuratData::InstallData("stxBrain")
pbmc.data <- Read10X(data.dir = "https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_3k/pbmc_3k_filtered_gene_bc_matrices.tar.gz")
library(Seurat)
library(ggplot2)
library(patchwork)
pbmc.data <- Read10X(data.dir = "https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_3k/pbmc_3k_filtered_gene_bc_matrices.tar.gz")
install.packages("Seurat", dependencies = TRUE)
library(Seurat)
library(ggplot2)
library(patchwork)
pbmc.data <- Read10X(data.dir = "https://cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_3k/pbmc_3k_filtered_gene_bc_matrices.tar.gz")
library(SeuratData)
InstallData("pbmc3k")
data("pbmc3k")
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")
pbmc.data <- SeuratData::data("pbmc3k")
pbmc.data <- data("pbmc3k")
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k", min.cells = 3, min.features = 200)
pbmc.data <- GetAssayData(pbmc3k, slot = "counts")  # extract raw counts
pbmc <- CreateSeuratObject(counts = pbmc.data, project = "pbmc3k",
min.cells = 3, min.features = 200)
pbmc[["percent.mt"]] <- PercentageFeatureSet(pbmc, pattern = "^MT-")
VlnPlot(pbmc, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
pbmc <- subset(pbmc, subset = nFeature_RNA > 200 & nFeature_RNA < 2500 & percent.mt < 5)
pbmc <- NormalizeData(pbmc)
pbmc <- FindVariableFeatures(pbmc, selection.method = "vst", nfeatures = 2000)
head(VariableFeatures(pbmc))
pbmc <- ScaleData(pbmc)
pbmc <- RunPCA(pbmc, features = VariableFeatures(object = pbmc))
ElbowPlot(pbmc)     # See how much information is retained in the first few principal components
VizDimLoadings(pbmc, dims = 1:2)  # Check which genes contribute most to the first and second principal
DimPlot(pbmc, reduction = "pca")
library(tidyverse)
library(DESeq2)
install.packages("tidyverse", "DESeq2", "ComplexHeatmap", "RColorBrewer", "GenomicRanges")
install.packages("tidyverse")
library("tidyverse")
install.packages("DESeq2")
BiocManager::install("DESeq2")
library(DESeq2)
install.packages("ComplexHeatmap")
library(ComplexHeatmap)
BiocManager::install("ComplexHeatmap")
BiocManager::install("ComplexHeatmap")
library(ComplexHeatmap)
install.packages("RColorBrewer")
install.packages("RColorBrewer")
ibrary(RColorBrewer)
BiocManager::install("RColorBrewer")
library
library(RColorBrewer)
install.packages("GenomicRanges")
BiocManager::install(GenomicRanges")
BiocManager::install("GenomicRanges")
library(GenomicRanges)
BiocManager::install("MOFA2")
library(MOFA2)
counts <- read.csv("https://figshare.com/ndownloader/files/26020911", row.names = 1)
BiocManager::install("mixOmics")
library(mixOmics)
library(MOFA2)
library(dplyr)
library(ggplot2)
set.seed(123)
n_samples <- 50
n_genes <- 100
n_proteins <- 80
transcriptomics <- matrix(rnorm(n_samples * n_genes, mean=10, sd=2), nrow=n_samples)
rownames(transcriptomics) <- paste0("Sample_", 1:n_samples)
colnames(transcriptomics) <- paste0("Gene_", 1:n_genes)
transcriptomics
proteomics <- matrix(rnorm(n_samples * n_proteins, mean=5, sd=1.5), nrow=n_samples)
rownames(proteomics) <- paste0("Sample_", 1:n_samples)
colnames(proteomics) <- paste0("Protein_", 1:n_proteins)
proteomics
transcriptomics_norm <- log2(transcriptomics + 1)
transcriptomics_norm
proteomics_norm <- scale(proteomics)
proteomics_norm
# 3. Canonical Correlation Analysis (CCA) with mixOmics
# Prepare data for CCA
X <- transcriptomics_norm
Y <- proteomics_norm
# Perform CCA
cca_result <- rcc(X, Y, ncomp=2, lambda1=0.1, lambda2=0.1)
cca_result
plotVar(cca_result, var.names = FALSE, cex = 0.5,
title = "CCA Correlation Circle Plot")
# Option 1: Simple vector
plotVar(cca_result, var.names = FALSE, cex = c(0.5, 0.5),
title = "CCA Correlation Circle Plot")
mofa_data <- list(
Transcriptomics = t(transcriptomics_norm),
Proteomics = t(proteomics_norm)
)
mofa_model <- create_mofa(mofa_data)
mofa_model
mofa_options <- get_default_model_options(mofa_model)
mofa_options$num_factors <- 10
mofa_options$scale_views <- TRUE
# Train MOFA model
mofa_trained <- run_mofa(mofa_model, mofa_options)
# Prepare the MOFA model for training
mofa_model <- prepare_mofa(mofa_model, mofa_options)
# Prepare data for MOFA
mofa_data <- list(
Transcriptomics = t(transcriptomics_norm),
Proteomics = t(proteomics_norm)
)
# Create MOFA object
mofa_model <- create_mofa(mofa_data)
# Set model options
mofa_options <- get_default_model_options(mofa_model)
mofa_options$num_factors <- 10
mofa_options$scale_views <- TRUE
# Set data options
data_options <- get_default_data_options(mofa_model)
# Optional: Customize data options if needed
data_options$scale <- TRUE  # Scale data to unit variance
data_options$center <- TRUE # Center data
# Prepare MOFA model with both data and model options
mofa_model <- prepare_mofa(mofa_model, data_options = data_options, model_options = mofa_options)
# Prepare data for MOFA
mofa_data <- list(
Transcriptomics = t(transcriptomics_norm),
Proteomics = t(proteomics_norm)
)
# Create MOFA object
mofa_model <- create_mofa(mofa_data)
# Set model options
mofa_options <- get_default_model_options(mofa_model)
mofa_options$num_factors <- 10
mofa_options$scale_views <- TRUE
# Set data options
data_options <- get_default_data_options(mofa_model)
# Optional: Customize data options if needed
data_options$scale <- TRUE  # Scale data to unit variance
data_options$center <- TRUE # Center data
# Prepare MOFA model with both data and model options
mofa_model <- prepare_mofa(mofa_model, data_options = data_options, model_options = mofa_options)
# Load required libraries
library(MOFA2)
# Prepare data for MOFA (ensure correct format: features as rows, samples as columns)
mofa_data <- list(
Transcriptomics = t(transcriptomics_norm), # 100 genes x 50 samples
Proteomics = t(proteomics_norm)           # 80 proteins x 50 samples
)
# Verify data dimensions and no missing values
cat("Dimensions of Transcriptomics:", dim(mofa_data$Transcriptomics), "\n")
cat("Dimensions of Proteomics:", dim(mofa_data$Proteomics), "\n")
cat("Missing values in Transcriptomics:", sum(is.na(mofa_data$Transcriptomics)), "\n")
cat("Missing values in Proteomics:", sum(is.na(mofa_data$Proteomics)), "\n")
mofa_model <- create_mofa(mofa_data)
# Set data options
data_options <- get_default_data_options(mofa_model)
# Explicitly set key options
data_options$scale <- TRUE   # Scale data to unit variance
data_options$center <- TRUE  # Center data by subtracting the mean
data_options$use_samples <- NULL  # Use all samples
data_options$use_features <- NULL  # Use all features
# Set model options
mofa_options <- get_default_model_options(mofa_model)
mofa_options$num_factors <- 10
mofa_options$scale_views <- TRUE
# Prepare MOFA model
mofa_model <- prepare_mofa(mofa_model,
data_options = data_options,
model_options = mofa_options)
set.seed(123)
n_samples <- 50
n_genes <- 100
rna_seq <- matrix(rnorm(n_samples * n_genes, mean=10, sd=2), nrow=n_samples)
rownames(rna_seq) <- paste0("Sample_", 1:n_samples)
colnames(rna_seq) <- paste0("Gene_", 1:n_genes)
# Simulate genomic data (50 samples, 200 SNPs, encoded as 0/1/2)
n_snps <- 200
genomic <- matrix(sample(0:2, n_samples * n_snps, replace=TRUE), nrow=n_samples)
rownames(genomic) <- paste0("Sample_", 1:n_samples)
colnames(genomic) <- paste0("SNP_", 1:n_snps)
# Preprocess data
rna_seq_norm <- log2(rna_seq + 1)  # Log-transform RNA-seq
genomic_norm <- scale(genomic)     # Standardize SNP data
rna_seq_norm
genomic_norm
# Perform sparse PLS for integration
spls_result <- spls(X = rna_seq_norm, Y = genomic_norm, ncomp = 2,
keepX = c(10, 10), keepY = c(20, 20))  # Select 10 genes, 20 SNPs per component
# Visualize with correlation circle plot
plotVar(spls_result, var.names = FALSE, cex = c(0.5, 0.5),
title = "sPLS Correlation Circle Plot: RNA-seq vs Genomic")
pls_result <- spls(X = rna_seq_norm, Y = genomic_norm, ncomp = 2,
keepX = c(10, 10), keepY = c(20, 20))  # Select 10 genes, 20 SNPs per component
# Visualize correlation circle plot
plotVar(spls_result, var.names = FALSE, cex = c(0.5, 0.5),
title = "sPLS Correlation Circle Plot: RNA-seq vs Genomic")
spls_loadings_X <- selectVar(spls_result, comp = 1)$X  # Top genes
spls_loadings_Y <- selectVar(spls_result, comp = 1)$Y  # Top SNPs
cat("Top 10 RNA-seq genes (Component 1):\n")
print(head(spls_loadings_X, 10))
cat("Top 20 SNPs (Component 1):\n")
print(head(spls_loadings_Y, 20))
# 4. DIABLO for supervised multi-omics integration
# Prepare data as a named list for DIABLO
data_list <- list(RNAseq = rna_seq_norm, Genomic = genomic_norm)
# Design matrix for supervised analysis (binary outcome)
design <- matrix(0.1, nrow = 2, ncol = 2,
dimnames = list(c("RNAseq", "Genomic"), c("RNAseq", "Genomic")))
diag(design) <- 0  # Focus on outcome, not block correlations
# Run DIABLO
diablo_result <- block.splsda(X = data_list, Y = outcome, ncomp = 2,
keepX = list(RNAseq = c(10, 10), Genomic = c(20, 20)))
# 4. DIABLO for supervised multi-omics integration
# Prepare data as a named list for DIABLO
data_list <- list(RNAseq = rna_seq_norm, Genomic = genomic_norm)
# Design matrix for supervised analysis (binary outcome)
design <- matrix(0.1, nrow = 2, ncol = 2,
dimnames = list(c("RNAseq", "Genomic"), c("RNAseq", "Genomic")))
diag(design) <- 0  # Focus on outcome, not block correlations
diablo_result <- block.splsda(X = data_list, Y = outcome, ncomp = 2,
keepX = list(RNAseq = c(10, 10), Genomic = c(20, 20)))
rna_seq <- matrix(rnorm(n_samples * n_genes, mean=10, sd=2), nrow=n_samples)
rownames(rna_seq) <- paste0("Sample_", 1:n_samples)
colnames(rna_seq) <- paste0("Gene_", 1:n_genes)
# Simulated genomic data (SNPs)
genomic <- matrix(sample(0:2, n_samples * n_snps, replace=TRUE), nrow=n_samples)
rownames(genomic) <- paste0("Sample_", 1:n_samples)
colnames(genomic) <- paste0("SNP_", 1:n_snps)
# Define outcome (binary factor for supervised analysis)
outcome <- factor(sample(c("Disease", "Control"), n_samples, replace=TRUE),
levels = c("Disease", "Control"))
# 2. Preprocess data
rna_seq_norm <- log2(rna_seq + 1)  # Log-transform RNA-seq
genomic_norm <- scale(genomic)     # Standardize SNP data
# 3. Prepare data for DIABLO
data_list <- list(RNAseq = rna_seq_norm, Genomic = genomic_norm)
# Design matrix for DIABLO (focus on outcome prediction)
design <- matrix(0.1, nrow = 2, ncol = 2,
dimnames = list(c("RNAseq", "Genomic"), c("RNAseq", "Genomic")))
diag(design) <- 0  # Emphasize outcome over block correlations
# 4. Run DIABLO
diablo_result <- block.splsda(X = data_list, Y = outcome, ncomp = 2,
keepX = list(RNAseq = c(10, 10), Genomic = c(20, 20)))
# 5. Visualize sample plot
plotIndiv(diablo_result, ind.names = FALSE, legend = TRUE,
title = "DIABLO Sample Plot by Outcome")
# 6. Extract top biomarkers
diablo_biomarkers_RNAseq <- selectVar(diablo_result, block = "RNAseq", comp = 1)$RNAseq
diablo_biomarkers_Genomic <- selectVar(diablo_result, block = "Genomic", comp = 1)$Genomic
cat("Top 10 RNA-seq biomarkers (Component 1):\n")
print(head(diablo_biomarkers_RNAseq, 10))
cat("Top 20 Genomic biomarkers (Component 1):\n")
print(head(diablo_biomarkers_Genomic, 20))
run_basic_qc <- function(seurat_obj, mito_pattern = "^MT-") {
seurat_obj[["percent.mt"]] <- Seurat::PercentageFeatureSet(seurat_obj, pattern = mito_pattern)
qc_metrics <- Seurat::FetchData(seurat_obj, vars = c("nFeature_RNA", "nCount_RNA", "percent.mt"))
return(qc_metrics)
}
run_isolation_forest_qc <- function(seurat_obj, python_path = NULL) {
if (!is.null(python_path)) reticulate::use_python(python_path)
reticulate::py_install("pyod", pip = TRUE)
py <- reticulate::import("pyod.models.iforest", convert = TRUE)
qc_data <- Seurat::FetchData(seurat_obj, vars = c("nFeature_RNA", "nCount_RNA", "percent.mt"))
clf <- py$IForest()
clf$fit(qc_data)
scores <- clf$decision_scores_
return(scores)
}
LoadPBMC2k <- function(dev_path = NULL) {
if (!is.null(dev_path)) {
data_path <- dev_path
} else {
data_path <- system.file("extdata", "pbmc2k.csv", package = "HybridQC")
}
if (data_path == "" || !file.exists(data_path)) {
stop("pbmc2k.csv not found. If testing locally, provide dev_path = 'inst/extdata/pbmc2k.csv'")
}
counts <- read.csv(data_path, row.names = 1, check.names = FALSE)
seurat_obj <- Seurat::CreateSeuratObject(counts = as.matrix(counts))
return(seurat_obj)
}
seurat_obj <- LoadPBMC2K()
seurat_obj <- LoadPBMC2k()
LoadPBMC2k <- function(dev_path = NULL) {
if (!is.null(dev_path)) {
data_path <- dev_path
} else {
data_path <- system.file("extdata", "pbmc2k.csv", package = "HybridQC")
}
if (data_path == "" || !file.exists(data_path)) {
stop("pbmc2k.csv not found. If testing locally, provide dev_path = 'inst/extdata/pbmc2k.csv'")
}
counts <- read.csv(data_path, row.names = 1, check.names = FALSE)
seurat_obj <- Seurat::CreateSeuratObject(counts = as.matrix(counts))
return(seurat_obj)
}
run_basic_qc <- function(seurat_obj, mito_pattern = "^MT-") {
seurat_obj[["percent.mt"]] <- Seurat::PercentageFeatureSet(seurat_obj, pattern = mito_pattern)
qc_metrics <- Seurat::FetchData(seurat_obj, vars = c("nFeature_RNA", "nCount_RNA", "percent.mt"))
return(qc_metrics)
}
filter_cells <- function(seurat_obj, basic_qc, ml_scores, ml_threshold = NULL) {
if (is.null(ml_threshold)) {
ml_threshold <- quantile(ml_scores, 0.95)  # top 5% outliers
}
keep <- ml_scores < ml_threshold
return(subset(seurat_obj, cells = colnames(seurat_obj)[keep]))
}
run_isolation_forest_qc <- function(seurat_obj, python_path = NULL) {
if (!is.null(python_path)) reticulate::use_python(python_path)
reticulate::py_install("pyod", pip = TRUE)
py <- reticulate::import("pyod.models.iforest", convert = TRUE)
qc_data <- Seurat::FetchData(seurat_obj, vars = c("nFeature_RNA", "nCount_RNA", "percent.mt"))
clf <- py$IForest()
clf$fit(qc_data)
scores <- clf$decision_scores_
return(scores)
}
LoadPBMC2k <- function(dev_path = NULL) {
if (!is.null(dev_path)) {
data_path <- dev_path
} else {
data_path <- system.file("extdata", "pbmc2k.csv", package = "HybridQC")
}
if (data_path == "" || !file.exists(data_path)) {
stop("pbmc2k.csv not found. If testing locally, provide dev_path = 'inst/extdata/pbmc2k.csv'")
}
counts <- read.csv(data_path, row.names = 1, check.names = FALSE)
seurat_obj <- Seurat::CreateSeuratObject(counts = as.matrix(counts))
return(seurat_obj)
}
seurat_obj <- LoadPBMC2k()
install.packages("Biostrings")
install.packages("ShortRead")
install.packages("dplyr")
install.packages("RCurl")
BiocManager::install("ShortRead")
BiocManager::install("Biostrings")
library(Biostrings)    # for DNA sequence handling
library(ShortRead)     # for FASTQ parsing
library(RCurl)         # for downloading reference data
library(BLAST)         # system call to BLAST+
BiocManager::install("BLAST")
library(BLAST)
install.packages("BLAST")
setwd("/Users/kl/Work/Applications/AMRScan")
input_fastq <- "data/GCA_037966445.1_ASM3796644v1_genomic.fna"
output_dir <- "results/"
db_url <- "https://card.mcmaster.ca/latest/data"  # Example source
db_fasta <- "card_db.fasta"  # local filename
blast_db <- "card_blastdb"
if (!dir.exists(output_dir)) dir.create(output_dir)
# Determine input file type
file_ext <- tools::file_ext(input_fastq)
input_fasta <- NULL
if (file_ext == "fastq") {
cat("Detected FASTQ input. Performing quality filtering and conversion to FASTA...\n")
fq <- readFastq(input_fastq)
fq_trimmed <- fq[quality(fq) >= 20]
writeFastq(fq_trimmed, file = paste0(output_dir, "cleaned.fastq"))
seqs <- sread(fq_trimmed)
names(seqs) <- as.character(id(fq_trimmed))
input_fasta <- paste0(output_dir, "cleaned.fasta")
writeXStringSet(DNAStringSet(seqs), filepath = input_fasta)
} else if (file_ext %in% c("fa", "fasta")) {
cat("Detected FASTA input. Skipping quality filtering.\n")
input_fasta <- input_fastq
} else {
stop("Unsupported input format. Please provide a .fastq or .fasta file.")
}
if (file_ext == "fastq") {
cat("Detected FASTQ input. Performing quality filtering and conversion to FASTA...\n")
fq <- readFastq(input_fastq)
fq_trimmed <- fq[quality(fq) >= 20]
writeFastq(fq_trimmed, file = paste0(output_dir, "cleaned.fastq"))
seqs <- sread(fq_trimmed)
names(seqs) <- as.character(id(fq_trimmed))
input_fasta <- paste0(output_dir, "cleaned.fasta")
writeXStringSet(DNAStringSet(seqs), filepath = input_fasta)
} else if (file_ext %in% c("fa", "fna", "fasta")) {
cat("Detected FASTA input. Skipping quality filtering.\n")
input_fasta <- input_fastq
} else {
stop("Unsupported input format. Please provide a .fastq or .fasta file.")
}
if (!file.exists(db_fasta)) {
download.file(paste0(db_url, "/protein_fasta_protein_homolog_model.fasta"), db_fasta)
system(paste("makeblastdb -in", db_fasta, "-dbtype prot -out", blast_db))
}
if (file_ext == "fastq") {
cat("Detected FASTQ input. Performing quality filtering and conversion to FASTA...\n")
fq <- readFastq(input_fastq)
fq_trimmed <- fq[quality(fq) >= 20]
writeFastq(fq_trimmed, file = paste0(output_dir, "cleaned.fastq"))
seqs <- sread(fq_trimmed)
names(seqs) <- as.character(id(fq_trimmed))
input_fasta <- paste0(output_dir, "cleaned.fasta")
writeXStringSet(DNAStringSet(seqs), filepath = input_fasta)
} else if (file_ext %in% c("fa", "fna", "fasta")) {
cat("Detected FASTA input. Skipping quality filtering.\n")
input_fasta <- input_fastq
} else {
stop("Unsupported input format. Please provide a .fastq or .fasta file.")
}
# Step 2: Prepare CARD BLAST database
db_fasta <- "data/protein_fasta_protein_homolog_model.fasta"  # use local copy
blast_db <- "data/card_blastdb"  # store BLAST DB files in data/
if (!file.exists(paste0(blast_db, ".pin"))) {  # check if BLAST DB is built
cat("Preparing BLAST database from local CARD FASTA file...\n")
system(paste("makeblastdb -in", db_fasta, "-dbtype prot -out", blast_db))
} else {
cat("BLAST database already exists. Skipping makeblastdb.\n")
}
system(paste("blastx -query", paste0(output_dir, "cleaned.fasta"),
"-db", blast_db,
"-out", paste0(output_dir, "blast_results.tsv"),
"-outfmt '6 qseqid sseqid pident length evalue bitscore stitle'",
"-evalue 1e-5 -num_threads 4"))
cat("Running BLASTX on input FASTA:", input_fasta, "\n")
system(paste("blastx -query", input_fasta,
"-db", blast_db,
"-out", paste0(output_dir, "blast_results.tsv"),
"-outfmt '6 qseqid sseqid pident length evalue bitscore stitle'",
"-evalue 1e-5 -num_threads 4"))
blast_results <- read.delim(paste0(output_dir, "blast_results.tsv"), header = FALSE)
colnames(blast_results) <- c("Query", "Subject", "Identity", "Length", "Evalue", "Bitscore", "Annotation")
top_hits <- blast_results %>%
group_by(Query) %>%
top_n(1, Bitscore)
library(dplyr)
library(magrittr)  # for %>% pipe
top_hits <- blast_results %>%
group_by(Query) %>%
top_n(1, Bitscore)
write.csv(top_hits, file = paste0(output_dir, "AMR_hits_summary.csv"), row.names = FALSE)
input_file <- "data/GCF_037966445.1_ASM3796644v1_genomic.fna"
output_dir <- "results/"
db_url <- "https://card.mcmaster.ca/latest/data"  # Example source
db_fasta <- "card_db.fasta"  # local filename
blast_db <- "card_blastdb"
# Create output directory if it doesn’t exist
if (!dir.exists(output_dir)) dir.create(output_dir)
# Step 1: Preprocess FASTQ or FASTA
# Determine input file type
file_ext <- tools::file_ext(input_file)
input_fasta <- NULL
if (file_ext == "fastq") {
cat("Detected FASTQ input. Performing quality filtering and conversion to FASTA...\n")
fq <- readFastq(input_file)
fq_trimmed <- fq[quality(fq) >= 20]
writeFastq(fq_trimmed, file = paste0(output_dir, "cleaned.fastq"))
seqs <- sread(fq_trimmed)
names(seqs) <- as.character(id(fq_trimmed))
input_fasta <- paste0(output_dir, "cleaned.fasta")
writeXStringSet(DNAStringSet(seqs), filepath = input_fasta)
} else if (file_ext %in% c("fa", "fna", "fasta")) {
cat("Detected FASTA input. Skipping quality filtering.\n")
input_fasta <- input_file
} else {
stop("Unsupported input format. Please provide a .fastq or .fasta file.")
}
db_fasta <- "db_demo/protein_fasta_protein_homolog_model.fasta"  # use local copy
blast_db <- "db_demo/card_blastdb"  # store BLAST DB files in data/
if (!file.exists(paste0(blast_db, ".pin"))) {  # check if BLAST DB is built
cat("Preparing BLAST database from local CARD FASTA file...\n")
system(paste("makeblastdb -in", db_fasta, "-dbtype prot -out", blast_db))
} else {
cat("BLAST database already exists. Skipping makeblastdb.\n")
}
cat("Running BLASTX on input FASTA:", input_fasta, "\n")
system(paste("blastx -query", input_fasta,
"-db", blast_db,
"-out", paste0(output_dir, "blast_results.tsv"),
"-outfmt '6 qseqid sseqid pident length evalue bitscore stitle'",
"-evalue 1e-5 -num_threads 4"))
blast_results <- read.delim(paste0(output_dir, "blast_results.tsv"), header = FALSE)
colnames(blast_results) <- c("Query", "Subject", "Identity", "Length", "Evalue", "Bitscore", "Annotation")
top_hits <- blast_results %>%
group_by(Query) %>%
top_n(1, Bitscore)
write.csv(top_hits, file = paste0(output_dir, "AMR_hits_summary.csv"), row.names = FALSE)
cat("AMRScan completed. Results saved to:", output_dir, "\n")
rmarkdown::render("AMRScan.Rmd")
rmarkdown::render("AMRScan.Rmd")
